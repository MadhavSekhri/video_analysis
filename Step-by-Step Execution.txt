Step-by-Step Execution

-----------------------------------------------------------------------------
Step 1: File Upload & Metadata Extraction

Input: User uploads a .mp4 file (via form-data).

Actions:
Generate one metadataId wrt Timestamp and our secretKey
Extract metadata using FFmpeg or a similar tool: duration, dimensions, fps, aspectRatio, fileSize.
Save the file temporarily on ec-2 instance to avoid additional network latency (later we would put it in a secure location in AWS S3 in async)
Note: We would be saving all files for one metadata in one folder {metdataId}
      Structure would look like
      -/static/uploads/{MetadataId}
          -{MetadataId}.mp4
          -{MetadataId}.mp3
          -{MetadataId}.xlsx
Insert basic metadata into the videoMetadata collection (status: pending).

Output:
videoMetadata document updated with initial data and status set to pending.

-----------------------------------------------------------------------------
Step 2: Audio Extraction

Input: .mp4 file.

Actions:
Extract audio from the video using FFmpeg.
Save the audio temporarily on ec-2 instance again to avoid additional network latency 

Output:
Audio file ready for transcription.
-----------------------------------------------------------------------------

Step 3: Audio Analysis

Input: Extracted audio file.

Actions:
Perform Speech-to-Text conversion using OpenAI Whisper.
Analyze transcribed text for-
Sentiment & tone: Use Hugging Face Transformers (BERT-based)-Distilbert
Harmful content: Use Perspective API.

Output:
Sentiment scores, harmful content flags (hate speech, NSFW terms, compliance violations, etc.).

-----------------------------------------------------------------------------
Step 4: Video Analysis

Input: Original .mp4 file.

Actions:
Detect objects and scenes using YOLOv8.
Analyze frames for NSFW content using pre-trained NSFW detection models(TensorFlow)
Check for regulatory violations using AWS Rekognition.

Output:
Visual flags (violent scenes, NSFW content, etc.) with timestamps.

-----------------------------------------------------------------------------

Step 5: Combine Audio & Video Analysis

Input: Outputs from Steps 3 & 4.

Actions:
Merge timestamps and detected issues into a unified format.
Generate a concise summary of all issues using Hugging Face Flan-T5.

Output:
Comprehensive summary (with timestamps) for the video.

-----------------------------------------------------------------------------

Step 6: Generate & Save Reports

Input: Analysis results (sentiment, harmful content, detected issues).

Actions:
Save the analysis in the analysis_videoMetadata collection.
Generate an Excel report with all data:
Metadata (e.g., duration, dimensions).
Audio analysis results.
Video analysis results.
Summarized issues.

Till now we would be having one .mp4 (original uploaded file), .mp3(extracted audio file) , .xlsx report(having all results) in one folder(based on MetadataId-Timestamp) sync this whole as an entity to S3 Bucket and remove from local

Output:
analysis_videoMetadata and updated videoMetadata document (status: processed, with reportUrl).

-----------------------------------------------------------------------------

Step 7: Track Bulk Upload Progress (if applicable)

Input: For multiple files.

Actions:
Track each video processing stage in the bulkupload_progressTracker collection.
Update progress after each stage (e.g., pending, processing, processed).

-----------------------------------------------------------------------------

Final Flow Summary:

User Uploads Video → Store file in Local → Extract Metadata → Save in videoMetadata.
Extract Audio → Perform Speech-to-Text → Analyze Audio.
Analyze Video → Detect Issues (NSFW, Violent, etc.).
Merge Results → Generate Summary → Save Analysis in db along with report.xlsx.
Generate Report → Save in S3 → Update videoMetadata with reportUrl.

Points:
-we can even think of clearing .mp3 and .mp4 files (even if not now but after a certain time)
-But For that we need to ask user certain more fields at the upload time like "Title" and "Label" or "Tags" (Keeping title to mandatory)
-So later when he comes to dashboard he should search or filter "Label wise"



